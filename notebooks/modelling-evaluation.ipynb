{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Report-Introduction\" data-toc-modified-id=\"Report-Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Report Introduction</a></span></li><li><span><a href=\"#Background\" data-toc-modified-id=\"Background-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Background</a></span></li><li><span><a href=\"#Modeling-Assumptions-and-Potential-Issues\" data-toc-modified-id=\"Modeling-Assumptions-and-Potential-Issues-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Modeling Assumptions and Potential Issues</a></span></li><li><span><a href=\"#Test-design\" data-toc-modified-id=\"Test-design-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Test design</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-the-Testing-and-Training-Datasets\" data-toc-modified-id=\"Creating-the-Testing-and-Training-Datasets-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Creating the Testing and Training Datasets</a></span><ul class=\"toc-item\"><li><span><a href=\"#One-Hot-Encoding-and-Minor-Manipulation\" data-toc-modified-id=\"One-Hot-Encoding-and-Minor-Manipulation-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>One Hot Encoding and Minor Manipulation</a></span></li><li><span><a href=\"#Test-Split-and-Scaling\" data-toc-modified-id=\"Test-Split-and-Scaling-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Test Split and Scaling</a></span></li></ul></li></ul></li><li><span><a href=\"#Models-Description-and-Assessments\" data-toc-modified-id=\"Models-Description-and-Assessments-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Models Description and Assessments</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Construction-and-Tuning\" data-toc-modified-id=\"Construction-and-Tuning-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Construction and Tuning</a></span></li><li><span><a href=\"#Interpretation\" data-toc-modified-id=\"Interpretation-5.1.3\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>Interpretation</a></span></li><li><span><a href=\"#Assessment\" data-toc-modified-id=\"Assessment-5.1.4\"><span class=\"toc-item-num\">5.1.4&nbsp;&nbsp;</span>Assessment</a></span></li></ul></li><li><span><a href=\"#Support-Vector-Machines-(SVM)\" data-toc-modified-id=\"Support-Vector-Machines-(SVM)-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Support Vector Machines (SVM)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Construction-and-Tuning\" data-toc-modified-id=\"Construction-and-Tuning-5.2.2\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;</span>Construction and Tuning</a></span></li><li><span><a href=\"#Interpretation\" data-toc-modified-id=\"Interpretation-5.2.3\"><span class=\"toc-item-num\">5.2.3&nbsp;&nbsp;</span>Interpretation</a></span></li><li><span><a href=\"#Detailed-assessment\" data-toc-modified-id=\"Detailed-assessment-5.2.4\"><span class=\"toc-item-num\">5.2.4&nbsp;&nbsp;</span>Detailed assessment</a></span></li></ul></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Random Forest</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Construction-and-Tuning\" data-toc-modified-id=\"Construction-and-Tuning-5.3.2\"><span class=\"toc-item-num\">5.3.2&nbsp;&nbsp;</span>Construction and Tuning</a></span></li><li><span><a href=\"#Interpretation\" data-toc-modified-id=\"Interpretation-5.3.3\"><span class=\"toc-item-num\">5.3.3&nbsp;&nbsp;</span>Interpretation</a></span></li><li><span><a href=\"#Assessment\" data-toc-modified-id=\"Assessment-5.3.4\"><span class=\"toc-item-num\">5.3.4&nbsp;&nbsp;</span>Assessment</a></span></li></ul></li></ul></li><li><span><a href=\"#Summary-of-Modelling\" data-toc-modified-id=\"Summary-of-Modelling-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Summary of Modelling</a></span></li><li><span><a href=\"#Evaluation-of-Data-Mining-Process\" data-toc-modified-id=\"Evaluation-of-Data-Mining-Process-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Evaluation of Data Mining Process</a></span><ul class=\"toc-item\"><li><span><a href=\"#Business-success-criteria\" data-toc-modified-id=\"Business-success-criteria-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Business success criteria</a></span></li><li><span><a href=\"#Review-of-project-success:\" data-toc-modified-id=\"Review-of-project-success:-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Review of project success:</a></span></li><li><span><a href=\"#Techniques-and-tools\" data-toc-modified-id=\"Techniques-and-tools-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Techniques and tools</a></span></li><li><span><a href=\"#Future-Work\" data-toc-modified-id=\"Future-Work-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Future Work</a></span></li></ul></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>References</a></span></li><li><span><a href=\"#Background\" data-toc-modified-id=\"Background-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Background</a></span></li><li><span><a href=\"#Modeling-assumptions\" data-toc-modified-id=\"Modeling-assumptions-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Modeling assumptions</a></span></li><li><span><a href=\"#Test-design\" data-toc-modified-id=\"Test-design-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Test design</a></span></li><li><span><a href=\"#Model-description-and-assessment\" data-toc-modified-id=\"Model-description-and-assessment-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Model description and assessment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Overview-of-models-produced.\" data-toc-modified-id=\"Overview-of-models-produced.-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;</span>Overview of models produced.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Type-of-model-and-relationship-to-data-mining-goals\" data-toc-modified-id=\"Type-of-model-and-relationship-to-data-mining-goals-12.1.1\"><span class=\"toc-item-num\">12.1.1&nbsp;&nbsp;</span>Type of model and relationship to data mining goals</a></span></li><li><span><a href=\"#Tuning-and-parameters\" data-toc-modified-id=\"Tuning-and-parameters-12.1.2\"><span class=\"toc-item-num\">12.1.2&nbsp;&nbsp;</span>Tuning and parameters</a></span></li><li><span><a href=\"#Detailed-description-of-the-model-and-any-special-features.\" data-toc-modified-id=\"Detailed-description-of-the-model-and-any-special-features.-12.1.3\"><span class=\"toc-item-num\">12.1.3&nbsp;&nbsp;</span>Detailed description of the model and any special features.</a></span></li></ul></li><li><span><a href=\"#Overview-of-assessment-process-and-results,-including-any-deviations-from-the-test-plan.-For-each-model:\" data-toc-modified-id=\"Overview-of-assessment-process-and-results,-including-any-deviations-from-the-test-plan.-For-each-model:-12.2\"><span class=\"toc-item-num\">12.2&nbsp;&nbsp;</span>Overview of assessment process and results, including any deviations from the test plan. For each model:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Detailed-assessment,-including-measurements-such-as-accuracy-and-interpretation-of-behavior\" data-toc-modified-id=\"Detailed-assessment,-including-measurements-such-as-accuracy-and-interpretation-of-behavior-12.2.1\"><span class=\"toc-item-num\">12.2.1&nbsp;&nbsp;</span>Detailed assessment, including measurements such as accuracy and interpretation of behavior</a></span></li><li><span><a href=\"#Insights-into-why-a-certain-modeling-technique-and-certain-parameter-settings-led-to-good/bad-results\" data-toc-modified-id=\"Insights-into-why-a-certain-modeling-technique-and-certain-parameter-settings-led-to-good/bad-results-12.2.2\"><span class=\"toc-item-num\">12.2.2&nbsp;&nbsp;</span>Insights into why a certain modeling technique and certain parameter settings led to good/bad results</a></span></li><li><span><a href=\"#Conclusions-regarding-patterns-in-the-data-(interpretation)\" data-toc-modified-id=\"Conclusions-regarding-patterns-in-the-data-(interpretation)-12.2.3\"><span class=\"toc-item-num\">12.2.3&nbsp;&nbsp;</span>Conclusions regarding patterns in the data (interpretation)</a></span></li></ul></li></ul></li><li><span><a href=\"#Summary-of-conclusions\" data-toc-modified-id=\"Summary-of-conclusions-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Summary of conclusions</a></span></li><li><span><a href=\"#Assessment-of-data-mining-results-with-respect-to-business-success-criteria\" data-toc-modified-id=\"Assessment-of-data-mining-results-with-respect-to-business-success-criteria-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Assessment of data mining results with respect to business success criteria</a></span><ul class=\"toc-item\"><li><span><a href=\"#Review-of-business-objectives-and-business-success-criteria-(which-may-have-changed-during-and/or-as-a-result-of-data-mining).\" data-toc-modified-id=\"Review-of-business-objectives-and-business-success-criteria-(which-may-have-changed-during-and/or-as-a-result-of-data-mining).-14.1\"><span class=\"toc-item-num\">14.1&nbsp;&nbsp;</span>Review of business objectives and business success criteria (which may have changed during and/or as a result of data mining).</a></span><ul class=\"toc-item\"><li><span><a href=\"#For-each-business-success-criterion:\" data-toc-modified-id=\"For-each-business-success-criterion:-14.1.1\"><span class=\"toc-item-num\">14.1.1&nbsp;&nbsp;</span>For each business success criterion:</a></span></li></ul></li><li><span><a href=\"#Review-of-project-success:\" data-toc-modified-id=\"Review-of-project-success:-14.2\"><span class=\"toc-item-num\">14.2&nbsp;&nbsp;</span>Review of project success:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Has-the-project-achieved-the-original-business-objectives?\" data-toc-modified-id=\"Has-the-project-achieved-the-original-business-objectives?-14.2.1\"><span class=\"toc-item-num\">14.2.1&nbsp;&nbsp;</span>Has the project achieved the original business objectives?</a></span></li><li><span><a href=\"#Are-there-new-business-objectives-to-be-addressed-later-in-the-project-or-in-new-projects?\" data-toc-modified-id=\"Are-there-new-business-objectives-to-be-addressed-later-in-the-project-or-in-new-projects?-14.2.2\"><span class=\"toc-item-num\">14.2.2&nbsp;&nbsp;</span>Are there new business objectives to be addressed later in the project or in new projects?</a></span></li></ul></li><li><span><a href=\"#Review-of-process\" data-toc-modified-id=\"Review-of-process-14.3\"><span class=\"toc-item-num\">14.3&nbsp;&nbsp;</span>Review of process</a></span></li><li><span><a href=\"#List-of-possible-actions:-make-recommendations-regarding-the-next-steps-in-the-project.\" data-toc-modified-id=\"List-of-possible-actions:-make-recommendations-regarding-the-next-steps-in-the-project.-14.4\"><span class=\"toc-item-num\">14.4&nbsp;&nbsp;</span>List of possible actions: make recommendations regarding the next steps in the project.</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"tocSkip\"><center class=\"tocSkip\">Modelling and Evaluation Report</center></h1>\n",
    "<h1 class=\"tocSkip\"><center class=\"tocSkip\"><i class=\"tocSkip\">Ammar Hasan 150454388</i></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "import sklearn.metrics as met\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "BASE_PROCESSED_DATA_DIR = '../data/processed'\n",
    "\"\"\"\n",
    "str: Base processed data directory\n",
    "\"\"\"\n",
    "\n",
    "PROCESSED_CSV_FILE = BASE_PROCESSED_DATA_DIR + '/processed.csv'\n",
    "\"\"\"\n",
    "str: HAM1000_metadata.csv metadata file location \n",
    "\"\"\"\n",
    "        \n",
    "# Read datasets in\n",
    "skin_df = pd.read_csv(PROCESSED_CSV_FILE, index_col=0)\n",
    "\n",
    "def tuning(function, parameters, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Used to tune a model using 5 cv\n",
    "    adapted from https://github.com/yuguan1/example-ML-code\n",
    "    \"\"\"\n",
    "    print(\"# Tuning hyper-parameters\")\n",
    "    clf = GridSearchCV(function, parameters, cv=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print('best parameters:')\n",
    "    print(clf.best_params_)\n",
    "    print('-------------------------------------')\n",
    "    return(clf.best_params_)\n",
    "\n",
    "def printMetrics(prediction, y_test):\n",
    "    \"\"\"\n",
    "    Prints accuracy, confusion and F1 metrics\n",
    "    \"\"\"\n",
    "    print('accuracy', met.accuracy_score(y_test, prediction))\n",
    "    print()\n",
    "    print(met.confusion_matrix(y_test, prediction))\n",
    "    print()\n",
    "    print('f1', met.f1_score(y_test, prediction, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning(function, parameters, X_train, y_train, n_iter = 20):\n",
    "    \"\"\"\n",
    "    Used to tune a model using 5 cv\n",
    "    adapted from https://github.com/yuguan1/example-ML-code\n",
    "    \"\"\"\n",
    "    print(\"# Tuning hyper-parameters\")\n",
    "    clf = RandomizedSearchCV(function,param_distributions=parameters, cv=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print('best parameters:')\n",
    "    print(clf.best_params_)\n",
    "    print('-------------------------------------')\n",
    "    return(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Introduction\n",
    "\n",
    "This report documents the Modelling and Evaluation stages of the CRISP-DM process followed by this project. This stage documents the construction of models and their evaluation - and to a lesser extent the project itself. This include background information about the models, their training, assessment and other evaluations. \n",
    "\n",
    "## Background \n",
    "\n",
    "As stated in the Business Understanding report the Pigment Skin Diagnosis field use of technology has been growing due critical importance of early detection, and the computerised detection of Skin Lesions is becoming critical. In this project as stated in the criteria of Business Understanding report, the objective of this project is to develop, train and evaluate models (logistic, SVM, neural) to classify skin lesion types and to compare the different models. \n",
    "\n",
    "## Modeling Assumptions and Potential Issues\n",
    "\n",
    "As stated in the Data Understanding report, some issues with the data were recognised:\n",
    "\n",
    "* Some of the sexes are unknown and the mention of whether these unknown sexes are simply unknown or are non-binary/non-conforming is missing.\n",
    "\n",
    "* Ground truths were obtained by various methods including expert consensus, which might effect the consistency of the classification.\n",
    "\n",
    "Hence, we need to assume that both the unknown sexes and the different methods to obtain the ground truth will not have a major impact on the modelling and its analysis.\n",
    "\n",
    "\n",
    "## Test design\n",
    "\n",
    "As alluded to before in the background, the following classification models will be built in this project: \n",
    "\n",
    "* A neural network - specifically a Convoluted Neural Network \n",
    "\n",
    "* Logistic Regression Model \n",
    "\n",
    "* A Support Vector Machine \n",
    "\n",
    "Models are fitted by using a training data set and if tuning is required 5 fold cross validation is also used to find the optimal parameters. To test models the testing data set is used after the model was trained to evaluate the model (accuracy, confusion, f1 score, etc). The Training and test data is created by splitting the post processed final dataset described in the Data Understanding report in a 50-50 split respectively.\n",
    "\n",
    "### Creating the Testing and Training Datasets\n",
    "\n",
    "The final dataset whose creation was described in the Data Preparation report needs minor changes before the modelling begins. In particular, the categorical variables need to be hot coded and the data needs to be divided into model training and model testing samples.\n",
    "\n",
    "#### One Hot Encoding and Minor Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical cols using one hot encoding\n",
    "\n",
    "one_hot_localization = pd.get_dummies(skin_df['localization'])\n",
    "one_hot_localization.drop('unknown', axis=1, inplace = True)\n",
    "\n",
    "one_hot_sex = pd.get_dummies(skin_df['sex'])\n",
    "one_hot_sex.drop('unknown', axis=1, inplace = True)\n",
    "\n",
    "# Drop old categorical cols and replace with new ones\n",
    "# drop dx type (not needed beyond data understanding)\n",
    "\n",
    "skin_df.drop(['dx_type', 'localization', 'sex'], axis = 1, inplace = True)\n",
    "\n",
    "# Join the encoded dfs\n",
    "\n",
    "skin_df = skin_df.join(one_hot_localization)\n",
    "skin_df = skin_df.join(one_hot_sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas dummies for categorical variables, localization values are one hot coded using new columns for every value (0 false / 1 true), however one of the columns is dropped a negation of all the other columns represents it. Lastly, the now redundant sex and localization fields are dropped alongside dx_type (no need for analysing diagnosis type beyond Data Understanding).\n",
    "\n",
    "#### Test Split and Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test data in a 50-50 split\n",
    "# Don't include lesion_types (used for response) and image path (not used yet)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    skin_df.drop(['lesion_type_idx', 'lesion_type', 'image_path'], axis=1),\n",
    "    skin_df['lesion_type_idx'], test_size=0.5, random_state=0)\n",
    "\n",
    "# scale using a partial fit for speed\n",
    "\n",
    "scaling = StandardScaler()\n",
    "\n",
    "scaling.partial_fit(X_test)\n",
    "X_test = scaling.transform(X_test)\n",
    "\n",
    "scaling.partial_fit(X_train)\n",
    "X_train = scaling.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data and the testing data are separated using a 60-40 split respectively, both sets consist of a set of predictors (X) and a response (y). The predictor data has the lesion_type_idx and lesion_type fields removed since they can leak the ground truth. For the response data only the lesion_type_idx field is used since it is sufficient at representing the category of skin lesion (the response / what is being predicted).\n",
    "\n",
    "To ensure that the impact of predictors is not effected by the measurement scale - which could occur in this dataset due to the variety of predictors, the predictors are scaled using a scaling transform (i.e. with default mean and standard deviation).\n",
    "\n",
    "## Models Description and Assessments\n",
    "\t\t\t\t\n",
    "### Logistic Regression \n",
    "\n",
    "#### Introduction \t\t\n",
    "\n",
    "To achieve its classification, Logistic Regression fits a line to separate the data into classes. The line is fitted by minimising the error between line and points by changing the coefficients/weights and the intercept to find the \"ideal fit\". To minimise the error gradient descent (i.e. loss function optimisation) is used, which updates the parameters (i.e. through partial derivatives) to find a local minimum/maximum. (James et al., 2013)\n",
    "\n",
    "#### Construction and Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and prediction\n",
    "clf = LogisticRegression(solver='saga', n_jobs = -1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously stated, logistic regression fits a line through error minimisation and does not require tuning as the objective is straightforward. The model is simply constructed using a saga solver deployed to 4 threads using sklearn's logistic regression model.\n",
    "\n",
    "Nonetheless, the constructed model does not seem to converge, this is not that surprising as the fitted line can have many solutions, and sometimes with a large number of predictors this can cause logistic regression to struggle (James et al., 2013).\n",
    "\n",
    "#### Interpretation\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form table for coefficients using column names\n",
    "\n",
    "coefs = pd.concat([pd.DataFrame(skin_df.drop(['lesion_type_idx','lesion_type','image_path'], axis = 1).columns),\n",
    "                   pd.DataFrame(np.transpose(clf.coef_))], axis = 1)\n",
    "                 \n",
    "# print table\n",
    "                   \n",
    "print(coefs.iloc[3136:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since as described in the introduction of logistic regression, logistic regression uses a set of coefficients and weights to draw the classification line, it is easy to interpret the model by examining them. However, since there are many predictors we only look at other meta data that is not directly related to the pixels.\n",
    "\n",
    "Here it can be seen that age is the strongest predictor, in particular with classes 1, 2 and 4 (Basal cell carcinoma, Benign keratosis and Melanocytic nevi respectively), where in classes 1 and 2 age had a positive impact, but in class 4 age had a strong negative one, some of these classes were predicted to have a strong dependence on age in the Data Understanding stage. Age seems to mostly have a positive trend nonetheless - which matches with the observations in the data understanding stage.\n",
    "\n",
    "When it comes to sex, three classes come to attention, classes 0, 4 and 5 (Actinic keratoses, Melanocytic nevi and melanoma respectively). In class 0, males have a noticiable positive impact which is also seen with class . In class 4 females have a noticiable negative impact. However, in comparison to age, the sexes impact is minor.\n",
    "\n",
    "For localization, the face seems to have a strong impact when it comes to class 0  (Actinic keratoses), also in class 2 ((Basal cell carcinoma), the face also has a strong impact on a classification in this class while the foot has the opposite effect. However, the classes mostly effected by localization are classes 4 (Melanocytic nevi) where a localization in the face very strongly suggests against a classification to class 4. Overall, localization is the second strongest predictor here.\n",
    "\n",
    "#### Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(X_test)\n",
    "printMetrics(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that while the overall accuracy is good, the F1 scores and poor except for class 5 (), this is worrying because as stated before in the business understanding false negative performance is important, and a poor F1 suggests a poor false negative performance as can be seen in the confusion table.\n",
    "\n",
    "This could be because of the issue observed in the model construction, as there was no convergence due to the large number of predictors perhaps. This might be fixed with the introduction of kernels as explained in the next section.\n",
    "\n",
    "### Support Vector Machines (SVM)\n",
    "\n",
    "#### Introduction \t\n",
    "\n",
    "Support Vector Machines are another classification model, which is an improvement logistic regression through the addition of two margins for the line which all class points must be behind and the distance to them from the line maximised (again using gradient descent). This ensures that the fairest line out of a set of lines that separate the points is chosen. Support Vector Machines can have the type of margins decided by parameter C, usually divided to either hard one with a large C (narrow with less points out of margin) or one soft with a smaller C (wider with more points out of margin). (Rieck et al., 2012)\n",
    "\n",
    "To help interpreting non linear data for SVMs, kernels (commonly a Raidial Bias Function (RBF)) transform the data to a higher dimension (kernel trick) (Rieck et al., 2012). Some Kernels take extra parameters, for example RBF takes a gamma parameter which controls the variance or influence of the Support Vector Machine (the higher the gamma the lower the variance) (“RBF SVM parameters — scikit-learn 0.20.2 documentation,” n.d.). \n",
    "\n",
    "#### Construction and Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "\n",
    "n_estimators = 5\n",
    "clf = OneVsRestClassifier(\n",
    "    BaggingClassifier(\n",
    "        SVC(kernel='rbf'),\n",
    "        max_samples=1.0 / n_estimators, n_estimators=n_estimators)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\t\t\t\t\t\n",
    "\n",
    "#### Detailed assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7114328507239142\n",
      "\n",
      "[[  13    4   20    1   77    5    0]\n",
      " [   7   35   16    0  144    8    0]\n",
      " [   4    6   98    0  295   15    0]\n",
      " [   3    3    6    0   39    1    0]\n",
      " [   2    3   21    0 2674    5    0]\n",
      " [   0    2   28    0  384   30    0]\n",
      " [   1    1    0    0   55    0    0]]\n",
      "\n",
      "f1 [0.17333333 0.26515152 0.32289951 0.         0.83916523 0.11811024\n",
      " 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Prediction \n",
    "\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "printMetrics(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Random Forest \n",
    "\n",
    "#### Introduction \t\t\n",
    "\n",
    "#### Construction and Tuning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [{'max_depth': [8,30,45],\n",
    "               'n_estimators': [150, 450, 550]}]\n",
    "\n",
    "# Tune parameters using 5 fold cross validation \n",
    "best_params = tuning(RandomForestClassifier(n_jobs = -1), parameters, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\t\t\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.concat(\n",
    "    [pd.DataFrame(skin_df.drop(['lesion_type_idx', 'lesion_type'], axis = 1).columns),\n",
    "                  pd.DataFrame(np.transpose(clf.feature_importances_))], axis = 1)\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and assesmenmt\n",
    "\n",
    "optimalDepth = best_params['max_depth']\n",
    "optimalEstimators = best_params['n_estimators']\n",
    "clf = RandomForestClassifier(max_depth = optimalDepth, n_estimators = optimalEstimators)\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "# Metrics (predtion vs Test response)\n",
    "printMetrics(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Modelling\n",
    "\n",
    "\n",
    "## Evaluation of Data Mining Process  \n",
    "\n",
    "\n",
    "### Business success criteria\n",
    "\t\t\t\t\n",
    "### Review of project success: \n",
    "\n",
    "### Techniques and tools \n",
    "\n",
    "### Future Work \n",
    "\n",
    "\n",
    "## References \n",
    "\n",
    "1. James, G., Witten, D., Hastie, T., Tibshirani, R., 2013. Classification, in: James, G., Witten, D., Hastie, T., Tibshirani, R. (Eds.), An Introduction to Statistical Learning: With Applications in R, Springer Texts in Statistics. Springer New York, New York, NY, pp. 127–173. https://doi.org/10.1007/978-1-4614-7138-7_4\n",
    "\n",
    "2. Rieck, K., Sonnenburg, S., Mika, S., Schäfer, C., Laskov, P., Tax, D., Müller, K.-R., 2012. Support Vector Machines, in: Gentle, J.E., Härdle, W.K., Mori, Y. (Eds.), Handbook of Computational Statistics: Concepts and Methods, Springer Handbooks of Computational Statistics. Springer Berlin Heidelberg, Berlin, Heidelberg, pp. 883–926. https://doi.org/10.1007/978-3-642-21551-3_30\n",
    "\n",
    "3. RBF SVM parameters — scikit-learn 0.20.2 documentation [WWW Document], n.d. URL https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html (accessed 1.19.19).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters\n",
      "best parameters:\n",
      "{'max_depth': 30, 'n_estimators': 550}\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        0         0\n",
      "0     pixel0000_rgb_28_28  0.002271\n",
      "1     pixel0001_rgb_28_28  0.000388\n",
      "2     pixel0002_rgb_28_28  0.000386\n",
      "3     pixel0003_rgb_28_28  0.002869\n",
      "4     pixel0004_rgb_28_28  0.000290\n",
      "5     pixel0005_rgb_28_28  0.000262\n",
      "6     pixel0006_rgb_28_28  0.001345\n",
      "7     pixel0007_rgb_28_28  0.000221\n",
      "8     pixel0008_rgb_28_28  0.000247\n",
      "9     pixel0009_rgb_28_28  0.002196\n",
      "10    pixel0010_rgb_28_28  0.000255\n",
      "11    pixel0011_rgb_28_28  0.000242\n",
      "12    pixel0012_rgb_28_28  0.001446\n",
      "13    pixel0013_rgb_28_28  0.000260\n",
      "14    pixel0014_rgb_28_28  0.000194\n",
      "15    pixel0015_rgb_28_28  0.000659\n",
      "16    pixel0016_rgb_28_28  0.000283\n",
      "17    pixel0017_rgb_28_28  0.000283\n",
      "18    pixel0018_rgb_28_28  0.000487\n",
      "19    pixel0019_rgb_28_28  0.000302\n",
      "20    pixel0020_rgb_28_28  0.000312\n",
      "21    pixel0021_rgb_28_28  0.000535\n",
      "22    pixel0022_rgb_28_28  0.000299\n",
      "23    pixel0023_rgb_28_28  0.000232\n",
      "24    pixel0024_rgb_28_28  0.000558\n",
      "25    pixel0025_rgb_28_28  0.000272\n",
      "26    pixel0026_rgb_28_28  0.000211\n",
      "27    pixel0027_rgb_28_28  0.000741\n",
      "28    pixel0028_rgb_28_28  0.000241\n",
      "29    pixel0029_rgb_28_28  0.000227\n",
      "...                   ...       ...\n",
      "3124    pixel0772_l_28_28  0.000200\n",
      "3125    pixel0773_l_28_28  0.000192\n",
      "3126    pixel0774_l_28_28  0.000176\n",
      "3127    pixel0775_l_28_28  0.000159\n",
      "3128    pixel0776_l_28_28  0.000246\n",
      "3129    pixel0777_l_28_28  0.000149\n",
      "3130    pixel0778_l_28_28  0.000130\n",
      "3131    pixel0779_l_28_28  0.000199\n",
      "3132    pixel0780_l_28_28  0.000244\n",
      "3133    pixel0781_l_28_28  0.000291\n",
      "3134    pixel0782_l_28_28  0.000426\n",
      "3135    pixel0783_l_28_28  0.000510\n",
      "3136                  age  0.011406\n",
      "3137           image_path  0.000045\n",
      "3138              abdomen  0.000000\n",
      "3139                acral  0.000076\n",
      "3140                 back  0.000050\n",
      "3141                chest  0.000022\n",
      "3142                  ear  0.003356\n",
      "3143                 face  0.000065\n",
      "3144                 foot  0.000001\n",
      "3145              genital  0.000050\n",
      "3146                 hand  0.000068\n",
      "3147      lower extremity  0.000046\n",
      "3148                 neck  0.000086\n",
      "3149                scalp  0.000058\n",
      "3150                trunk  0.000083\n",
      "3151      upper extremity  0.000055\n",
      "3152               female  0.000058\n",
      "3153                 male       NaN\n",
      "\n",
      "[3154 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "importances = pd.concat(\n",
    "    [pd.DataFrame(skin_df.drop(['lesion_type_idx', 'lesion_type'], axis = 1).columns),\n",
    "                  pd.DataFrame(np.transpose(clf.feature_importances_))], axis = 1)\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7240415335463258\n",
      "\n",
      "[[  18   26   54    0   58    1    0]\n",
      " [  13   74   41    0  127    4    0]\n",
      " [   6   22  197    0  298   14    0]\n",
      " [   0   12   16    0   36    0    0]\n",
      " [   2   15   62    0 3255   22    0]\n",
      " [   2    5   62    0  410   82    0]\n",
      " [   0    1    3    0   68    2    0]]\n",
      "\n",
      "f1 [0.18181818 0.35748792 0.40534979 0.         0.85567823 0.23906706\n",
      " 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# fit \n",
    "\n",
    "optimalDepth = best_params['max_depth']\n",
    "optimalEstimators = best_params['n_estimators']\n",
    "clf = RandomForestClassifier(max_depth = optimalDepth, n_estimators = optimalEstimators)\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "# Metrics (predtion vs Test response)\n",
    "printMetrics(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "Serveral modelling techniques are applied and tuned. Related to data peroration (different methods have different requirements)\n",
    "\n",
    "## Background \n",
    "\n",
    "outlines the modeling undertaken and its relationship to the data mining goals.\n",
    "\n",
    "## Modeling assumptions\n",
    "\n",
    "explicit assumptions made about the data and any assumptions that are implicit in the modeling technique to be used.\n",
    "\n",
    " \n",
    "## Test design\n",
    "\n",
    "how the models are built, tested, and evaluated: \n",
    "    * Type of model and the training data to be used\n",
    "\t* how the model will be tested or assessed (test data)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "## Model description and assessment\n",
    "\n",
    "describes the delivered models and overviews the process by which they were produced.\n",
    "\n",
    "\t\t\t\t\n",
    "### Overview of models produced.\n",
    "\n",
    "#### Type of model and relationship to data mining goals\n",
    "\t\t\t\t\t \n",
    "#### Tuning and parameters\n",
    "\t\t\t\t\t\n",
    "#### Detailed description of the model and any special features.\n",
    "\n",
    "Description of the model’s behavior and interpretation\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "### Overview of assessment process and results, including any deviations from the test plan. For each model:\n",
    "\n",
    "#### Detailed assessment, including measurements such as accuracy and interpretation of behavior \n",
    "\t\t\t\t\t\t\t\t\t\t \n",
    "#### Insights into why a certain modeling technique and certain parameter settings led to good/bad results \n",
    "#### Conclusions regarding patterns in the data (interpretation)\n",
    "\t\n",
    "\t\t\t\n",
    "## Summary of conclusions\n",
    "\n",
    "\n",
    "\t \n",
    "# Evaluation: \n",
    "\n",
    "Evaluate models and review the steps executed to create them, to be certain the model properly achieves the business objectives. A key objective is to determine if there is some important business issue that has not been sufficiently considered. At the end of this phase, a decision on the use of the data mining results should be reached.\n",
    "\n",
    "\t\t\t\n",
    "## Assessment of data mining results with respect to business success criteria\n",
    " \n",
    "### Review of business objectives and business success criteria (which may have changed during and/or as a result of data mining).\n",
    "\t\t\t\t\t\n",
    "#### For each business success criterion:\n",
    "\t\t\t\t\t\t\n",
    "Detailed comparison between success criterion and data mining results\n",
    "\t\t\t\t\t\t\n",
    "Conclusions about achievability of success criterion and suitability of data mining process\n",
    "\t\t\t\t\n",
    "### Review of project success: \n",
    "\n",
    "\t\t\t\t\t\n",
    "#### Has the project achieved the original business objectives? \n",
    "\t\t\t\t\t\n",
    "#### Are there new business objectives to be addressed later in the project or in new projects?\n",
    "\t\t\t\t\t\n",
    "Conclusions for future data mining projects\n",
    "\t\t\t\n",
    "### Review of process\n",
    "\n",
    "assesses the effectiveness of the project and identifies any factors that may have been overlooked that should be taken into consideration if the project is repeated.\n",
    "\t\t\n",
    "### List of possible actions: make recommendations regarding the next steps in the project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
