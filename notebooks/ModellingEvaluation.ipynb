{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Report-Introduction\" data-toc-modified-id=\"Report-Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Report Introduction</a></span></li><li><span><a href=\"#Background\" data-toc-modified-id=\"Background-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Background</a></span></li><li><span><a href=\"#Modeling-Assumptions-and-Potential-Issues\" data-toc-modified-id=\"Modeling-Assumptions-and-Potential-Issues-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Modeling Assumptions and Potential Issues</a></span></li><li><span><a href=\"#Test-design\" data-toc-modified-id=\"Test-design-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Test design</a></span></li><li><span><a href=\"#Models-Description-and-Assessments\" data-toc-modified-id=\"Models-Description-and-Assessments-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Models Description and Assessments</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Construction-and-Tuning\" data-toc-modified-id=\"Construction-and-Tuning-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Construction and Tuning</a></span></li></ul></li></ul></li><li><span><a href=\"#Report-Introduction\" data-toc-modified-id=\"Report-Introduction-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Report Introduction</a></span></li><li><span><a href=\"#Background\" data-toc-modified-id=\"Background-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Background</a></span></li><li><span><a href=\"#Modeling-Assumptions-and-Potential-Issues\" data-toc-modified-id=\"Modeling-Assumptions-and-Potential-Issues-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Modeling Assumptions and Potential Issues</a></span></li><li><span><a href=\"#Test-design\" data-toc-modified-id=\"Test-design-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Test design</a></span></li><li><span><a href=\"#Models-Description-and-Assessments\" data-toc-modified-id=\"Models-Description-and-Assessments-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Models Description and Assessments</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-10.1.1\"><span class=\"toc-item-num\">10.1.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Tuning-and-parameters\" data-toc-modified-id=\"Tuning-and-parameters-10.1.2\"><span class=\"toc-item-num\">10.1.2&nbsp;&nbsp;</span>Tuning and parameters</a></span></li><li><span><a href=\"#Interpretation\" data-toc-modified-id=\"Interpretation-10.1.3\"><span class=\"toc-item-num\">10.1.3&nbsp;&nbsp;</span>Interpretation</a></span></li><li><span><a href=\"#Detailed-assessment\" data-toc-modified-id=\"Detailed-assessment-10.1.4\"><span class=\"toc-item-num\">10.1.4&nbsp;&nbsp;</span>Detailed assessment</a></span></li></ul></li><li><span><a href=\"#Support-Vector-Machine-(SVM)\" data-toc-modified-id=\"Support-Vector-Machine-(SVM)-10.2\"><span class=\"toc-item-num\">10.2&nbsp;&nbsp;</span>Support Vector Machine (SVM)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-10.2.1\"><span class=\"toc-item-num\">10.2.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Tuning-and-parameters\" data-toc-modified-id=\"Tuning-and-parameters-10.2.2\"><span class=\"toc-item-num\">10.2.2&nbsp;&nbsp;</span>Tuning and parameters</a></span></li><li><span><a href=\"#Interpretation\" data-toc-modified-id=\"Interpretation-10.2.3\"><span class=\"toc-item-num\">10.2.3&nbsp;&nbsp;</span>Interpretation</a></span></li><li><span><a href=\"#Detailed-assessment\" data-toc-modified-id=\"Detailed-assessment-10.2.4\"><span class=\"toc-item-num\">10.2.4&nbsp;&nbsp;</span>Detailed assessment</a></span></li></ul></li><li><span><a href=\"#Convoluted-Neural-Network-(CNN)\" data-toc-modified-id=\"Convoluted-Neural-Network-(CNN)-10.3\"><span class=\"toc-item-num\">10.3&nbsp;&nbsp;</span>Convoluted Neural Network (CNN)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-10.3.1\"><span class=\"toc-item-num\">10.3.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Tuning-and-parameters\" data-toc-modified-id=\"Tuning-and-parameters-10.3.2\"><span class=\"toc-item-num\">10.3.2&nbsp;&nbsp;</span>Tuning and parameters</a></span></li><li><span><a href=\"#Interpretation\" data-toc-modified-id=\"Interpretation-10.3.3\"><span class=\"toc-item-num\">10.3.3&nbsp;&nbsp;</span>Interpretation</a></span></li><li><span><a href=\"#Detailed-assessment\" data-toc-modified-id=\"Detailed-assessment-10.3.4\"><span class=\"toc-item-num\">10.3.4&nbsp;&nbsp;</span>Detailed assessment</a></span></li></ul></li></ul></li><li><span><a href=\"#Summary-of-Modelling\" data-toc-modified-id=\"Summary-of-Modelling-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Summary of Modelling</a></span></li><li><span><a href=\"#Evaluation-of-Data-Mining-Process\" data-toc-modified-id=\"Evaluation-of-Data-Mining-Process-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Evaluation of Data Mining Process</a></span><ul class=\"toc-item\"><li><span><a href=\"#Business-success-criteria\" data-toc-modified-id=\"Business-success-criteria-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;</span>Business success criteria</a></span></li><li><span><a href=\"#Review-of-project-success:\" data-toc-modified-id=\"Review-of-project-success:-12.2\"><span class=\"toc-item-num\">12.2&nbsp;&nbsp;</span>Review of project success:</a></span></li><li><span><a href=\"#Techniques-and-tools\" data-toc-modified-id=\"Techniques-and-tools-12.3\"><span class=\"toc-item-num\">12.3&nbsp;&nbsp;</span>Techniques and tools</a></span></li><li><span><a href=\"#Future-Work\" data-toc-modified-id=\"Future-Work-12.4\"><span class=\"toc-item-num\">12.4&nbsp;&nbsp;</span>Future Work</a></span></li></ul></li><li><span><a href=\"#Background\" data-toc-modified-id=\"Background-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Background</a></span></li><li><span><a href=\"#Modeling-assumptions\" data-toc-modified-id=\"Modeling-assumptions-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Modeling assumptions</a></span></li><li><span><a href=\"#Test-design\" data-toc-modified-id=\"Test-design-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Test design</a></span></li><li><span><a href=\"#Model-description-and-assessment\" data-toc-modified-id=\"Model-description-and-assessment-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>Model description and assessment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Overview-of-models-produced.\" data-toc-modified-id=\"Overview-of-models-produced.-16.1\"><span class=\"toc-item-num\">16.1&nbsp;&nbsp;</span>Overview of models produced.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Type-of-model-and-relationship-to-data-mining-goals\" data-toc-modified-id=\"Type-of-model-and-relationship-to-data-mining-goals-16.1.1\"><span class=\"toc-item-num\">16.1.1&nbsp;&nbsp;</span>Type of model and relationship to data mining goals</a></span></li><li><span><a href=\"#Tuning-and-parameters\" data-toc-modified-id=\"Tuning-and-parameters-16.1.2\"><span class=\"toc-item-num\">16.1.2&nbsp;&nbsp;</span>Tuning and parameters</a></span></li><li><span><a href=\"#Detailed-description-of-the-model-and-any-special-features.\" data-toc-modified-id=\"Detailed-description-of-the-model-and-any-special-features.-16.1.3\"><span class=\"toc-item-num\">16.1.3&nbsp;&nbsp;</span>Detailed description of the model and any special features.</a></span></li></ul></li><li><span><a href=\"#Overview-of-assessment-process-and-results,-including-any-deviations-from-the-test-plan.-For-each-model:\" data-toc-modified-id=\"Overview-of-assessment-process-and-results,-including-any-deviations-from-the-test-plan.-For-each-model:-16.2\"><span class=\"toc-item-num\">16.2&nbsp;&nbsp;</span>Overview of assessment process and results, including any deviations from the test plan. For each model:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Detailed-assessment,-including-measurements-such-as-accuracy-and-interpretation-of-behavior\" data-toc-modified-id=\"Detailed-assessment,-including-measurements-such-as-accuracy-and-interpretation-of-behavior-16.2.1\"><span class=\"toc-item-num\">16.2.1&nbsp;&nbsp;</span>Detailed assessment, including measurements such as accuracy and interpretation of behavior</a></span></li><li><span><a href=\"#Insights-into-why-a-certain-modeling-technique-and-certain-parameter-settings-led-to-good/bad-results\" data-toc-modified-id=\"Insights-into-why-a-certain-modeling-technique-and-certain-parameter-settings-led-to-good/bad-results-16.2.2\"><span class=\"toc-item-num\">16.2.2&nbsp;&nbsp;</span>Insights into why a certain modeling technique and certain parameter settings led to good/bad results</a></span></li><li><span><a href=\"#Conclusions-regarding-patterns-in-the-data-(interpretation)\" data-toc-modified-id=\"Conclusions-regarding-patterns-in-the-data-(interpretation)-16.2.3\"><span class=\"toc-item-num\">16.2.3&nbsp;&nbsp;</span>Conclusions regarding patterns in the data (interpretation)</a></span></li></ul></li></ul></li><li><span><a href=\"#Summary-of-conclusions\" data-toc-modified-id=\"Summary-of-conclusions-17\"><span class=\"toc-item-num\">17&nbsp;&nbsp;</span>Summary of conclusions</a></span></li><li><span><a href=\"#Assessment-of-data-mining-results-with-respect-to-business-success-criteria\" data-toc-modified-id=\"Assessment-of-data-mining-results-with-respect-to-business-success-criteria-18\"><span class=\"toc-item-num\">18&nbsp;&nbsp;</span>Assessment of data mining results with respect to business success criteria</a></span><ul class=\"toc-item\"><li><span><a href=\"#Review-of-business-objectives-and-business-success-criteria-(which-may-have-changed-during-and/or-as-a-result-of-data-mining).\" data-toc-modified-id=\"Review-of-business-objectives-and-business-success-criteria-(which-may-have-changed-during-and/or-as-a-result-of-data-mining).-18.1\"><span class=\"toc-item-num\">18.1&nbsp;&nbsp;</span>Review of business objectives and business success criteria (which may have changed during and/or as a result of data mining).</a></span><ul class=\"toc-item\"><li><span><a href=\"#For-each-business-success-criterion:\" data-toc-modified-id=\"For-each-business-success-criterion:-18.1.1\"><span class=\"toc-item-num\">18.1.1&nbsp;&nbsp;</span>For each business success criterion:</a></span></li></ul></li><li><span><a href=\"#Review-of-project-success:\" data-toc-modified-id=\"Review-of-project-success:-18.2\"><span class=\"toc-item-num\">18.2&nbsp;&nbsp;</span>Review of project success:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Has-the-project-achieved-the-original-business-objectives?\" data-toc-modified-id=\"Has-the-project-achieved-the-original-business-objectives?-18.2.1\"><span class=\"toc-item-num\">18.2.1&nbsp;&nbsp;</span>Has the project achieved the original business objectives?</a></span></li><li><span><a href=\"#Are-there-new-business-objectives-to-be-addressed-later-in-the-project-or-in-new-projects?\" data-toc-modified-id=\"Are-there-new-business-objectives-to-be-addressed-later-in-the-project-or-in-new-projects?-18.2.2\"><span class=\"toc-item-num\">18.2.2&nbsp;&nbsp;</span>Are there new business objectives to be addressed later in the project or in new projects?</a></span></li></ul></li><li><span><a href=\"#Review-of-process\" data-toc-modified-id=\"Review-of-process-18.3\"><span class=\"toc-item-num\">18.3&nbsp;&nbsp;</span>Review of process</a></span></li><li><span><a href=\"#List-of-possible-actions:-make-recommendations-regarding-the-next-steps-in-the-project.\" data-toc-modified-id=\"List-of-possible-actions:-make-recommendations-regarding-the-next-steps-in-the-project.-18.4\"><span class=\"toc-item-num\">18.4&nbsp;&nbsp;</span>List of possible actions: make recommendations regarding the next steps in the project.</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 class=\"tocSkip\"><center class=\"tocSkip\">Modelling and Evaluation Report</center></h1>\n",
    "<h1 class=\"tocSkip\"><center class=\"tocSkip\"><i class=\"tocSkip\">Ammar Hasan 150454388</i></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as pre\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import sklearn.metrics as met\n",
    "\n",
    "BASE_PROCESSED_DATA_DIR = '../data/processed'\n",
    "\"\"\"\n",
    "str: Base processed data directory\n",
    "\"\"\"\n",
    "\n",
    "PROCESSED_CSV_FILE = BASE_PROCESSED_DATA_DIR + '/processed.csv'\n",
    "\"\"\"\n",
    "str: HAM1000_metadata.csv metadata file location \n",
    "\"\"\"\n",
    "        \n",
    "# Read datasets in\n",
    "skin_df = pd.read_csv(PROCESSED_CSV_FILE, index_col=0)\n",
    "\n",
    "# Code adapted from https://github.com/yuguan1/example-ML-code\n",
    "## tuning method (5 cv)\n",
    "def tuning(function, parameters):\n",
    "    print(\"# Tuning hyper-parameters\")\n",
    "    clf = GridSearchCV(function, parameters, cv=5)\n",
    "    clf.fit(sTrainPred, trainRes)\n",
    "\n",
    "    print('best parameters:')\n",
    "    print(clf.best_params_)\n",
    "    print('-------------------------------------')\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "\n",
    "## print metrics (Accuracy, confusion, f1)\n",
    "def printMetrics(prediction, y_test):\n",
    "    print('accuracy', met.accuracy_score(y_test, prediction))\n",
    "    print()\n",
    "    print(met.confusion_matrix(y_test, prediction))\n",
    "    print()\n",
    "    print('f1', met.f1_score(y_test, prediction, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print metrics (Accuracy, confusion, f1)\n",
    "def printMetrics(prediction, y_test):\n",
    "    print('accuracy', met.accuracy_score(y_test, prediction))\n",
    "    print()\n",
    "    print(met.confusion_matrix(y_test, prediction))\n",
    "    print()\n",
    "    print('f1', met.f1_score(y_test, prediction, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Introduction\n",
    "\n",
    "This report documents the Modelling and Evaluation stages of the CRISP-DM process followed by this project. This stage documents the construction of models and their evaluation - and to a lesser extent the project itself. This include background information about the models, their training, assessment and other evaluations. \n",
    "\n",
    "## Background \n",
    "\n",
    "As stated in the Business Understanding report the Pigment Skin Diagnosis field use of technology has been growing due critical importance of early detection, and the computerised detection of Skin Lesions is becoming critical. In this project as stated in the criteria of Business Understanding report, the objective of this project is to develop, train and evaluate models (logistic, SVM, neural) to classify skin lesion types and to compare the different models. \n",
    "\n",
    "## Modeling Assumptions and Potential Issues\n",
    "\n",
    "As stated in the Data Understanding report, some issues with the data were recognised:\n",
    "\n",
    "* Some of the sexes are unknown and the mention of whether these unknown sexes are simply unknown or are non-binary/non-conforming is missing.\n",
    "\n",
    "* Ground truths were obtained by various methods including expert consensus, which might effect the consistency of the classification.\n",
    "\n",
    "Hence, we need to assume that both the unknown sexes and the different methods to obtain the ground truth will not have a major impact on the modelling and its analysis.\n",
    "\n",
    "\n",
    "## Test design\n",
    "\n",
    "As alluded to before in the background, the following classification models will be built in this project: \n",
    "\n",
    "* A neural network - specifically a Convoluted Neural Network \n",
    "\n",
    "* Logistic Regression Model \n",
    "\n",
    "* A Support Vector Machine \n",
    "\n",
    "Models are fitted by using cross validation (10 fold) and if tuning is required 10 fold cross validation is also used to find the optimal parameters. To test models. \n",
    "\n",
    "The data used for training and testing is provided from the post process metadata dataset described in the Data Understanding report. \n",
    "\n",
    "\t\t\t\t\t\t\t\t\n",
    "## Models Description and Assessments\n",
    "\t\t\t\t\n",
    "### Logistic Regression \n",
    "\n",
    "#### Introduction \t\t\n",
    "\n",
    "To achieve its classification, Logistic Regression fits a line to separate the data into classes. The line is fitted by minimising the error between line and points by changing the coefficients/weights and the intercept to find the \"ideal fit\". To minimise the error gradient descent (i.e. loss function optimisation) is used, which updates the parameters (i.e. through partial derivatives) to find a local minimum/maximum. (James et al., 2013)\n",
    "\n",
    "#### Construction and Tuning \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical cols using one hot encoding\n",
    "\n",
    "one_hot_localization = pd.get_dummies(skin_df['localization'])\n",
    "one_hot_localization.drop('neck', axis=1, inplace = True)\n",
    "\n",
    "one_hot_sex = pd.get_dummies(skin_df['sex'])\n",
    "one_hot_sex.drop('unknown', axis=1, inplace = True)\n",
    "\n",
    "one_hot_dx_type = pd.get_dummies(skin_df['dx_type'])\n",
    "one_hot_dx_type.drop('histo', axis=1, inplace = True)\n",
    "\n",
    "# Drop old categorical cols and replace with new ones\n",
    "\n",
    "skin_df.drop(['dx_type', 'localization', 'sex'], axis = 1, inplace = True)\n",
    "\n",
    "# Join the encoded dfs\n",
    "skin_df = skin_df.join(one_hot_localization)\n",
    "skin_df = skin_df.join(one_hot_dx_type)\n",
    "skin_df = skin_df.join(one_hot_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['lesion_id' 'image_id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-59c0f6fa3f36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mskin_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lesion_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'image_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3695\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3696\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3697\u001b[1;33m                                            errors=errors)\n\u001b[0m\u001b[0;32m   3698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3699\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3109\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3110\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3111\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3141\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3142\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3143\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3144\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   4402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4403\u001b[0m                 raise KeyError(\n\u001b[1;32m-> 4404\u001b[1;33m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[0;32m   4405\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4406\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['lesion_id' 'image_id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "skin_df.drop(['lesion_id', 'image_id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = np.array_split(skin_df, 2)\n",
    "\n",
    "X_train = split_df[0].loc[:, split_df[0].columns != 'dx']\n",
    "X_test = split_df[1].loc[:, split_df[1].columns != 'dx']\n",
    "y_train = split_df[0]['dx']\n",
    "y_test = split_df[1]['dx']\n",
    "\n",
    "# Fit and prediction\n",
    "clf = LogisticRegression().fit(\n",
    "    X_train.loc[:, X_train.columns != 'image_path'], y_train, solver='sag', n_jobs = 3)\n",
    "prediction = clf.predict(X_test.loc[:, X_train.columns != 'image_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.3628919512682245\n",
      "\n",
      "[[   0   87  113   23   77   17   10]\n",
      " [   0    0    0    0    0    0    0]\n",
      " [   0    0    2    0    2    0    0]\n",
      " [   0    0    0    0    0    0    0]\n",
      " [   0    1    1    0    2    0    0]\n",
      " [   0  301  869   89 1511 1813   89]\n",
      " [   0    0    0    0    0    0    0]]\n",
      "\n",
      "f1 [0.         0.         0.00404449 0.         0.00250627 0.55767456\n",
      " 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Metrics (predtion vs Test response)\n",
    "printMetrics(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As previously stated, logistic regression fits a line through error minimisation and does not require tuning as the objective is straightforward. \n",
    "\n",
    "#### Interpretation\t\t\n",
    "\n",
    "#### Detailed assessment\n",
    "\t\t\t\t\t\t\t\t\t\t \n",
    "### Support Vector Machines (SVM)\n",
    "\n",
    "#### Introduction \t\n",
    "\n",
    "Support Vector Machines are another classification model, which is an improvement logistic regression through the addition of two margins for the line which all class points must be behind and the distance to them from the line maximised (again using gradient descent). This ensures that the fairest line out of a set of lines that separate the points is chosen. Support Vector Machines can have the type of margins decided by parameter C, usually divided to either hard one with a large C (narrow with less points out of margin) or one soft with a smaller C (wider with more points out of margin). (Rieck et al., 2012)\n",
    "\n",
    "To help interpreting non linear data for SVMs, kernels (commonly a Raidial Bias Function (RBF)) transform the data to a higher dimension (kernel trick). Some Kernels take extra parameters, for example RBF takes a gamma parameter which controls the variance or influence of the Support Vector Machine (the higher the gamma the lower the variance) (“RBF SVM parameters — scikit-learn 0.20.2 documentation,” n.d.). \n",
    "\n",
    "#### Construction and Tuning \n",
    "#### Interpretation\t\t\t\t\t\n",
    "#### Detailed assessment\n",
    "\n",
    "### Convoluted Neural Network (CNN)\n",
    "\n",
    "#### Introduction \t\t\t\t \n",
    "#### Construction and Tuning \n",
    "#### Interpretation\t\t\t\t\t\n",
    "#### Detailed assessment\n",
    "\n",
    "\t\n",
    "## Summary of Modelling\n",
    "\n",
    "\n",
    "## Evaluation of Data Mining Process  \n",
    "\n",
    "\n",
    "### Business success criteria\n",
    "\t\t\t\t\n",
    "### Review of project success: \n",
    "\n",
    "### Techniques and tools \n",
    "\n",
    "### Future Work \n",
    "\n",
    "\n",
    "## References \n",
    "\n",
    "1. James, G., Witten, D., Hastie, T., Tibshirani, R., 2013. Classification, in: James, G., Witten, D., Hastie, T., Tibshirani, R. (Eds.), An Introduction to Statistical Learning: With Applications in R, Springer Texts in Statistics. Springer New York, New York, NY, pp. 127–173. https://doi.org/10.1007/978-1-4614-7138-7_4\n",
    "\n",
    "2. Rieck, K., Sonnenburg, S., Mika, S., Schäfer, C., Laskov, P., Tax, D., Müller, K.-R., 2012. Support Vector Machines, in: Gentle, J.E., Härdle, W.K., Mori, Y. (Eds.), Handbook of Computational Statistics: Concepts and Methods, Springer Handbooks of Computational Statistics. Springer Berlin Heidelberg, Berlin, Heidelberg, pp. 883–926. https://doi.org/10.1007/978-3-642-21551-3_30\n",
    "\n",
    "3. RBF SVM parameters — scikit-learn 0.20.2 documentation [WWW Document], n.d. URL https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html (accessed 1.19.19).\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "Serveral modelling techniques are applied and tuned. Related to data peroration (different methods have different requirements)\n",
    "\n",
    "## Background \n",
    "\n",
    "outlines the modeling undertaken and its relationship to the data mining goals.\n",
    "\n",
    "## Modeling assumptions\n",
    "\n",
    "explicit assumptions made about the data and any assumptions that are implicit in the modeling technique to be used.\n",
    "\n",
    " \n",
    "## Test design\n",
    "\n",
    "how the models are built, tested, and evaluated: \n",
    "    * Type of model and the training data to be used\n",
    "\t* how the model will be tested or assessed (test data)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "## Model description and assessment\n",
    "\n",
    "describes the delivered models and overviews the process by which they were produced.\n",
    "\n",
    "\t\t\t\t\n",
    "### Overview of models produced.\n",
    "\n",
    "#### Type of model and relationship to data mining goals\n",
    "\t\t\t\t\t \n",
    "#### Tuning and parameters\n",
    "\t\t\t\t\t\n",
    "#### Detailed description of the model and any special features.\n",
    "\n",
    "Description of the model’s behavior and interpretation\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "### Overview of assessment process and results, including any deviations from the test plan. For each model:\n",
    "\n",
    "#### Detailed assessment, including measurements such as accuracy and interpretation of behavior \n",
    "\t\t\t\t\t\t\t\t\t\t \n",
    "#### Insights into why a certain modeling technique and certain parameter settings led to good/bad results \n",
    "#### Conclusions regarding patterns in the data (interpretation)\n",
    "\t\n",
    "\t\t\t\n",
    "## Summary of conclusions\n",
    "\n",
    "\n",
    "\t \n",
    "# Evaluation: \n",
    "\n",
    "Evaluate models and review the steps executed to create them, to be certain the model properly achieves the business objectives. A key objective is to determine if there is some important business issue that has not been sufficiently considered. At the end of this phase, a decision on the use of the data mining results should be reached.\n",
    "\n",
    "\t\t\t\n",
    "## Assessment of data mining results with respect to business success criteria\n",
    " \n",
    "### Review of business objectives and business success criteria (which may have changed during and/or as a result of data mining).\n",
    "\t\t\t\t\t\n",
    "#### For each business success criterion:\n",
    "\t\t\t\t\t\t\n",
    "Detailed comparison between success criterion and data mining results\n",
    "\t\t\t\t\t\t\n",
    "Conclusions about achievability of success criterion and suitability of data mining process\n",
    "\t\t\t\t\n",
    "### Review of project success: \n",
    "\n",
    "\t\t\t\t\t\n",
    "#### Has the project achieved the original business objectives? \n",
    "\t\t\t\t\t\n",
    "#### Are there new business objectives to be addressed later in the project or in new projects?\n",
    "\t\t\t\t\t\n",
    "Conclusions for future data mining projects\n",
    "\t\t\t\n",
    "### Review of process\n",
    "\n",
    "assesses the effectiveness of the project and identifies any factors that may have been overlooked that should be taken into consideration if the project is repeated.\n",
    "\t\t\n",
    "### List of possible actions: make recommendations regarding the next steps in the project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
